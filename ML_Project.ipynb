{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\program files\\python\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "d:\\program files\\python\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('jigsaw-toxic-comment-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1788392"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = train.sample(frac=0.6, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ всех дополнительных колонок тональности (как проявляется тот или иной тип токсичности, как в данных это представлено, какие есть пограничные случаи) - 2.5 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80477.000000</td>\n",
       "      <td>80477.000000</td>\n",
       "      <td>80477.000000</td>\n",
       "      <td>80477.000000</td>\n",
       "      <td>80477.000000</td>\n",
       "      <td>80477.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.096748</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.009841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.295616</td>\n",
       "      <td>0.092330</td>\n",
       "      <td>0.228581</td>\n",
       "      <td>0.057612</td>\n",
       "      <td>0.220497</td>\n",
       "      <td>0.098715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              toxic  severe_toxic       obscene        threat        insult  \\\n",
       "count  80477.000000  80477.000000  80477.000000  80477.000000  80477.000000   \n",
       "mean       0.096748      0.008599      0.055308      0.003330      0.051244   \n",
       "std        0.295616      0.092330      0.228581      0.057612      0.220497   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "90%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "91%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "95%        1.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "99%        1.000000      0.000000      1.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       identity_hate  \n",
       "count   80477.000000  \n",
       "mean        0.009841  \n",
       "std         0.098715  \n",
       "min         0.000000  \n",
       "50%         0.000000  \n",
       "90%         0.000000  \n",
       "91%         0.000000  \n",
       "95%         0.000000  \n",
       "99%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe(percentiles=[.90, .91, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, the proportion of toxic ccomments is very small (less than 10% of all comments, and severe toxic comments less than 1%). Among them, obscene and insult account for more, while threat and identity hate account for less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.284561</td>\n",
       "      <td>0.700516</td>\n",
       "      <td>0.166405</td>\n",
       "      <td>0.669892</td>\n",
       "      <td>0.284180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxic</th>\n",
       "      <td>0.284561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369589</td>\n",
       "      <td>0.144123</td>\n",
       "      <td>0.345792</td>\n",
       "      <td>0.217031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscene</th>\n",
       "      <td>0.700516</td>\n",
       "      <td>0.369589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.147367</td>\n",
       "      <td>0.758092</td>\n",
       "      <td>0.300787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.166405</td>\n",
       "      <td>0.144123</td>\n",
       "      <td>0.147367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150901</td>\n",
       "      <td>0.107855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.669892</td>\n",
       "      <td>0.345792</td>\n",
       "      <td>0.758092</td>\n",
       "      <td>0.150901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_hate</th>\n",
       "      <td>0.284180</td>\n",
       "      <td>0.217031</td>\n",
       "      <td>0.300787</td>\n",
       "      <td>0.107855</td>\n",
       "      <td>0.350760</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  toxic  severe_toxic   obscene    threat    insult  \\\n",
       "toxic          1.000000      0.284561  0.700516  0.166405  0.669892   \n",
       "severe_toxic   0.284561      1.000000  0.369589  0.144123  0.345792   \n",
       "obscene        0.700516      0.369589  1.000000  0.147367  0.758092   \n",
       "threat         0.166405      0.144123  0.147367  1.000000  0.150901   \n",
       "insult         0.669892      0.345792  0.758092  0.150901  1.000000   \n",
       "identity_hate  0.284180      0.217031  0.300787  0.107855  0.350760   \n",
       "\n",
       "               identity_hate  \n",
       "toxic               0.284180  \n",
       "severe_toxic        0.217031  \n",
       "obscene             0.300787  \n",
       "threat              0.107855  \n",
       "insult              0.350760  \n",
       "identity_hate       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The toxic comments correlate more with obscene and insult. The lowest correlation is with threat. \n",
    "\n",
    "2) In severe toxic correlations look similar, but with lower values. \n",
    "\n",
    "3) Obscene most of all correlates with insult, the lowest correlation is with threats. \n",
    "\n",
    "4) Threat have little correlation with all indicators. Exclude toxic and severe toxic, the highest is with insult, the lowest is with identity hate.\n",
    "\n",
    "5) Insult correlates most with obscene, and least with threat. \n",
    "\n",
    "6) Identity hate most of all correlates with insults but the correlation is not very high. The lowest is with threat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from string import punctuation\n",
    "punct = punctuation + '«…»'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/lwahomura/ML/blob/master/Exam_sharing.ipynb\n",
    "def soft_normalize(text):\n",
    "  text = re.sub(\"\\n|\\t|\\s\\\"\", \" \", text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "  text = re.sub(f\"[{punct}]\", \" \", text)\n",
    "  text = re.sub(\"\\s+\", \" \", text)\n",
    "  return text.split()\n",
    "\n",
    "# the average number of tokens in comment text\n",
    "def tokens_count(text):\n",
    "  return len(tokenize(text))\n",
    "\n",
    "# the average length of tokens in comment text\n",
    "def mean_tokens_length(text):\n",
    "  tokens = tokenize(text)\n",
    "  length = 0\n",
    "  if len(tokens) == 0:\n",
    "    return 0\n",
    "  for t in tokens:\n",
    "    length += len(t)\n",
    "  return length/len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenize(text):\n",
    "  sents = re.split(\"[\\n.!?]( |$)\", text)\n",
    "  return [s for s in sents if len(s) > 0 and s != \" \"]\n",
    "\n",
    "# the average number of sentences in comment text\n",
    "def sents_count(text):\n",
    "  return len(sentenize(text))\n",
    "\n",
    "# the average length of sentences in comment text\n",
    "def mean_sents_length(text):\n",
    "  sents = sentenize(text)\n",
    "  length = 0\n",
    "  if len(sents) == 0:\n",
    "    return 0\n",
    "  for s in sents:\n",
    "    length += len(tokenize(s))\n",
    "  return length/len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caps_count(text):\n",
    "  caps = [ch for ch in text if ch.isupper()]\n",
    "  return len(caps)\n",
    "\n",
    "def caps_ratio(text):\n",
    "  ratio = caps_count(text)/len(text)\n",
    "  return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_normalized'] = train['comment_text'].apply(soft_normalize)\n",
    "\n",
    "train['text_tokens_count'] = train['text_normalized'].apply(tokens_count)\n",
    "train['text_mean_tokens_length'] = train['text_normalized'].apply(mean_tokens_length)\n",
    "\n",
    "train['text_sents_count'] = train['text_normalized'].apply(sents_count)\n",
    "train['text_mean_sents_length'] = train['text_normalized'].apply(mean_sents_length)\n",
    "\n",
    "train['text_caps_count'] = train['text_normalized'].apply(caps_count)\n",
    "train['text_caps_ratio'] = train['text_normalized'].apply(caps_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>text_normalized</th>\n",
       "      <th>text_tokens_count</th>\n",
       "      <th>text_mean_tokens_length</th>\n",
       "      <th>text_sents_count</th>\n",
       "      <th>text_mean_sents_length</th>\n",
       "      <th>text_caps_count</th>\n",
       "      <th>text_caps_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11037</th>\n",
       "      <td>1d2b1540745088a2</td>\n",
       "      <td>\"\\n\\nOppose, slightly.  While I agree that the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  Oppose, slightly.  While I agree that the c...</td>\n",
       "      <td>94</td>\n",
       "      <td>4.319149</td>\n",
       "      <td>5</td>\n",
       "      <td>18.800000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.022989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167471</th>\n",
       "      <td>1fe2936972d58fa8</td>\n",
       "      <td>Yes, he's an academic lawyer, not an academic ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, he's an academic lawyer, not an academic ...</td>\n",
       "      <td>808</td>\n",
       "      <td>4.602723</td>\n",
       "      <td>31</td>\n",
       "      <td>26.064516</td>\n",
       "      <td>62</td>\n",
       "      <td>0.013234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172810</th>\n",
       "      <td>34bd41d7244721f0</td>\n",
       "      <td>here is a more general discription of a noob \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>here is a more general discription of a noob  ...</td>\n",
       "      <td>13</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51863</th>\n",
       "      <td>8ad014f3ea982dbf</td>\n",
       "      <td>Kakapo\\nKakapo seems to be a pretty decent art...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kakapo Kakapo seems to be a pretty decent arti...</td>\n",
       "      <td>54</td>\n",
       "      <td>3.796296</td>\n",
       "      <td>3</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.033457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94610</th>\n",
       "      <td>fcf2e3270691d13f</td>\n",
       "      <td>Your edit to Norman Cota \\n\\nPlease do not add...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your edit to Norman Cota   Please do not add n...</td>\n",
       "      <td>27</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147775</th>\n",
       "      <td>418fc291199679d9</td>\n",
       "      <td>TOM TERRY\\ndont tell me what to do.\\ni apologi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TOM TERRY dont tell me what to do. i apologize...</td>\n",
       "      <td>26</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>3</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>0.065041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32126</th>\n",
       "      <td>55612789b2cb5452</td>\n",
       "      <td>\":\"\"around 20,000\"\" is something you have made...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\":\"\"around 20,000\"\" is something you have made...</td>\n",
       "      <td>21</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164641</th>\n",
       "      <td>14897717438c761c</td>\n",
       "      <td>== Wikipedia:Wikiportal/Somalia/Featured artic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>== Wikipedia:Wikiportal/Somalia/Featured artic...</td>\n",
       "      <td>55</td>\n",
       "      <td>5.763636</td>\n",
       "      <td>2</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>00958dec64c33224</td>\n",
       "      <td>Please stop adding nonsense to Wikipedia. It i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Please stop adding nonsense to Wikipedia. It i...</td>\n",
       "      <td>22</td>\n",
       "      <td>4.954545</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57817</th>\n",
       "      <td>9ac50e13e8c8407c</td>\n",
       "      <td>Two Boys BUmming oohhhh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two Boys BUmming oohhhh</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19656</th>\n",
       "      <td>33ecb2e990e80e26</td>\n",
       "      <td>May 2006 (UTC)\\n\\nI agree Qaid-e-Azam has no r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>May 2006 (UTC)  I agree Qaid-e-Azam has no rel...</td>\n",
       "      <td>33</td>\n",
       "      <td>3.818182</td>\n",
       "      <td>3</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.066265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124942</th>\n",
       "      <td>9c7364712cce7312</td>\n",
       "      <td>C# doesn't have a criticism section. And all o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C# doesn't have a criticism section. And all o...</td>\n",
       "      <td>56</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.036184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218105</th>\n",
       "      <td>e9e559f02a6d59b1</td>\n",
       "      <td>Did I miss ya? \\n Not sure if you'll get this,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Did I miss ya?   Not sure if you'll get this, ...</td>\n",
       "      <td>61</td>\n",
       "      <td>4.098361</td>\n",
       "      <td>5</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132282</th>\n",
       "      <td>c3e6693c654aed36</td>\n",
       "      <td>Possibly unfree Image:Algerian_civil_war.jpg \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Possibly unfree Image:Algerian_civil_war.jpg  ...</td>\n",
       "      <td>80</td>\n",
       "      <td>4.725000</td>\n",
       "      <td>6</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58478</th>\n",
       "      <td>9c99cf3049435b5b</td>\n",
       "      <td>The same editor made the change again, but thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The same editor made the change again, but thi...</td>\n",
       "      <td>19</td>\n",
       "      <td>4.315789</td>\n",
       "      <td>2</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101739</th>\n",
       "      <td>2071726aff3fa68f</td>\n",
       "      <td>Thanks, and apologies for starting a new topic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks, and apologies for starting a new topic...</td>\n",
       "      <td>13</td>\n",
       "      <td>5.538462</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123485</th>\n",
       "      <td>948dc7c041e2465a</td>\n",
       "      <td>RfC on title of Sarah Brown (wife of Gordon Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RfC on title of Sarah Brown (wife of Gordon Br...</td>\n",
       "      <td>39</td>\n",
       "      <td>3.717949</td>\n",
       "      <td>2</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.073298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211130</th>\n",
       "      <td>cd94e2e8d460f446</td>\n",
       "      <td>\" \\n\\n :They are controversies within the scie...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"    :They are controversies within the scient...</td>\n",
       "      <td>64</td>\n",
       "      <td>5.046875</td>\n",
       "      <td>4</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183615</th>\n",
       "      <td>5fe443352a4dbef3</td>\n",
       "      <td>:Thanks for the note and promise not to repeat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>:Thanks for the note and promise not to repeat...</td>\n",
       "      <td>27</td>\n",
       "      <td>3.925926</td>\n",
       "      <td>2</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28111</th>\n",
       "      <td>4a653fe8d1811f79</td>\n",
       "      <td>Block \\nThanks im now unblocked</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Block  Thanks im now unblocked</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125271</th>\n",
       "      <td>9e0cca8d8ff27220</td>\n",
       "      <td>\"\\nI agree to some of your claims and apprecia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" I agree to some of your claims and appreciat...</td>\n",
       "      <td>290</td>\n",
       "      <td>4.482759</td>\n",
       "      <td>14</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>33</td>\n",
       "      <td>0.020258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75582</th>\n",
       "      <td>ca359b50852b7289</td>\n",
       "      <td>\"\\n\\nSockpuppetry case\\n \\nYou have been accus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  Sockpuppetry case   You have been accused o...</td>\n",
       "      <td>37</td>\n",
       "      <td>5.648649</td>\n",
       "      <td>4</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.035433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>116ac30b7b12be8c</td>\n",
       "      <td>To answer the question, he nominated way too e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>To answer the question, he nominated way too e...</td>\n",
       "      <td>50</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>4</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.038462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122401</th>\n",
       "      <td>8eb34c63e75edc5f</td>\n",
       "      <td>Your not gonna do the request?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Your not gonna do the request?</td>\n",
       "      <td>6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132470</th>\n",
       "      <td>c4cec2a10dfe4969</td>\n",
       "      <td>I notice the page history of the article was d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I notice the page history of the article was d...</td>\n",
       "      <td>21</td>\n",
       "      <td>4.238095</td>\n",
       "      <td>2</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.018018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198907</th>\n",
       "      <td>9cb5ff05e652b3df</td>\n",
       "      <td>Is there a source that says the destruction wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Is there a source that says the destruction wa...</td>\n",
       "      <td>30</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182053</th>\n",
       "      <td>5961b5e4e7cf7ba7</td>\n",
       "      <td>Sign your statements. Anyways, is this the epi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sign your statements. Anyways, is this the epi...</td>\n",
       "      <td>47</td>\n",
       "      <td>4.021277</td>\n",
       "      <td>2</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>6ab31f26b101a2f7</td>\n",
       "      <td>\" August 2009 (UTC)\\nOk, Nev1, it looks like S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" August 2009 (UTC) Ok, Nev1, it looks like Se...</td>\n",
       "      <td>152</td>\n",
       "      <td>3.927632</td>\n",
       "      <td>13</td>\n",
       "      <td>11.692308</td>\n",
       "      <td>51</td>\n",
       "      <td>0.065385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64491</th>\n",
       "      <td>ac957db1e0684d48</td>\n",
       "      <td>I have never seen a 'ben avelign' before.  Whe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I have never seen a 'ben avelign' before.  Whe...</td>\n",
       "      <td>45</td>\n",
       "      <td>4.422222</td>\n",
       "      <td>4</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.015810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146877</th>\n",
       "      <td>3300a643044afdec</td>\n",
       "      <td>, P.S. I love it when balls are in my face</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>, P.S. I love it when balls are in my face</td>\n",
       "      <td>11</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>2</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128952</th>\n",
       "      <td>b1a875d91f629169</td>\n",
       "      <td>\"\\n\\nSalut! As you allready saw, he is just wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  Salut! As you allready saw, he is just worr...</td>\n",
       "      <td>53</td>\n",
       "      <td>3.867925</td>\n",
       "      <td>7</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>6</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58395</th>\n",
       "      <td>9c54602199fc0523</td>\n",
       "      <td>ip 184, i'm sure you have read this, but pleas...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ip 184, i'm sure you have read this, but pleas...</td>\n",
       "      <td>100</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>5</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.024180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23620</th>\n",
       "      <td>3e627e043728cce0</td>\n",
       "      <td>or simple rules (any article with 'Day' in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>or simple rules (any article with 'Day' in the...</td>\n",
       "      <td>10</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.019231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209880</th>\n",
       "      <td>c897159b233d9d2a</td>\n",
       "      <td>If contracted/confirmed drivers aren't importa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If contracted/confirmed drivers aren't importa...</td>\n",
       "      <td>132</td>\n",
       "      <td>4.007576</td>\n",
       "      <td>8</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.020741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126330</th>\n",
       "      <td>a3a5b0fba516ed46</td>\n",
       "      <td>\"\\n\\nHere's why there was no consensus looking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  Here's why there was no consensus looking a...</td>\n",
       "      <td>90</td>\n",
       "      <td>4.822222</td>\n",
       "      <td>6</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.018116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7568</th>\n",
       "      <td>1421f5f258f434e4</td>\n",
       "      <td>Survey\\n\\nHi Brooke!\\n\\nI have put together a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Survey  Hi Brooke!  I have put together a surv...</td>\n",
       "      <td>135</td>\n",
       "      <td>4.674074</td>\n",
       "      <td>12</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.030227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30348</th>\n",
       "      <td>50936ee4686f7c8a</td>\n",
       "      <td>Someone told me! \\nSomeone told me that they w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Someone told me!  Someone told me that they wa...</td>\n",
       "      <td>22</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>0.032520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77211</th>\n",
       "      <td>cecc33e7ab1573de</td>\n",
       "      <td>Map also needs to be updated with new countries.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Map also needs to be updated with new countries.</td>\n",
       "      <td>9</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19044</th>\n",
       "      <td>324780da50cf8e52</td>\n",
       "      <td>\"\\n\\n Song move \\n\\nYou gave me some good advi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"   Song move   You gave me some good advice a...</td>\n",
       "      <td>277</td>\n",
       "      <td>4.036101</td>\n",
       "      <td>14</td>\n",
       "      <td>19.785714</td>\n",
       "      <td>76</td>\n",
       "      <td>0.051317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131312</th>\n",
       "      <td>be93869aa33a2b93</td>\n",
       "      <td>DWO:  Have you even been following the exchang...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DWO:  Have you even been following the exchang...</td>\n",
       "      <td>79</td>\n",
       "      <td>3.987342</td>\n",
       "      <td>7</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>24</td>\n",
       "      <td>0.058680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203763</th>\n",
       "      <td>b01eeb75aeadb901</td>\n",
       "      <td>GENOCIDE!! \\n this war is pur genocide....you ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GENOCIDE!!   this war is pur genocide....you m...</td>\n",
       "      <td>159</td>\n",
       "      <td>4.194969</td>\n",
       "      <td>2</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>29</td>\n",
       "      <td>0.032402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217057</th>\n",
       "      <td>e5aff0e9af237913</td>\n",
       "      <td>== Semi-protected edit request on 17 February ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>== Semi-protected edit request on 17 February ...</td>\n",
       "      <td>12</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77357</th>\n",
       "      <td>cf39a8635e6cfb13</td>\n",
       "      <td>UPDATE: tell me what proof I can give and I'll...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UPDATE: tell me what proof I can give and I'll...</td>\n",
       "      <td>15</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157358</th>\n",
       "      <td>dcbc819e13f7b9cb</td>\n",
       "      <td>. Also please see Talk:Fascism for a section I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>. Also please see Talk:Fascism for a section I...</td>\n",
       "      <td>14</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.054795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20548</th>\n",
       "      <td>363ce40d4ebc57c2</td>\n",
       "      <td>\"\\n\\nHello!  Because Chris Redfield is a chara...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  Hello!  Because Chris Redfield is a charact...</td>\n",
       "      <td>28</td>\n",
       "      <td>4.214286</td>\n",
       "      <td>4</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82413</th>\n",
       "      <td>dc80098c6b319680</td>\n",
       "      <td>\"\\nA poor reference is better than no referenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" A poor reference is better than no reference...</td>\n",
       "      <td>69</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>4</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42793</th>\n",
       "      <td>722dc7db8be28042</td>\n",
       "      <td>\"\\n\\n Cunt and \"\"7 Dirty Words\"\" \\n\\nIs the wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"   Cunt and \"7 Dirty Words\"\"   Is the word re...</td>\n",
       "      <td>51</td>\n",
       "      <td>5.058824</td>\n",
       "      <td>5</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.039514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81552</th>\n",
       "      <td>da1eb55349c101f9</td>\n",
       "      <td>nigger faggot \\n\\nread the entire reference be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nigger faggot   read the entire reference befo...</td>\n",
       "      <td>13</td>\n",
       "      <td>5.153846</td>\n",
       "      <td>1</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194528</th>\n",
       "      <td>8ba03ba99b545ac4</td>\n",
       "      <td>All God-fearing people are welcome here, infid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>All God-fearing people are welcome here, infid...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105085</th>\n",
       "      <td>322eab961b4dd2d1</td>\n",
       "      <td>\"\\n\\nI'm going to unprotect the article for th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  I'm going to unprotect the article for the ...</td>\n",
       "      <td>38</td>\n",
       "      <td>5.052632</td>\n",
       "      <td>4</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109678</th>\n",
       "      <td>4ab41d4570219461</td>\n",
       "      <td>I am a power hungry administrator! Who likes t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I am a power hungry administrator! Who likes t...</td>\n",
       "      <td>11</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>2</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134012</th>\n",
       "      <td>ccc987d2553050cb</td>\n",
       "      <td>\"\\nNow that all of the issues have been addres...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\" Now that all of the issues have been address...</td>\n",
       "      <td>23</td>\n",
       "      <td>4.521739</td>\n",
       "      <td>3</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.022222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137738</th>\n",
       "      <td>e115df0d9f164424</td>\n",
       "      <td>Interesting - thanks for this.  Suppose that I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Interesting - thanks for this.  Suppose that I...</td>\n",
       "      <td>122</td>\n",
       "      <td>4.180328</td>\n",
       "      <td>5</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25443</th>\n",
       "      <td>4359b2279ea01527</td>\n",
       "      <td>They complain about the drugs and tourist and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>They complain about the drugs and tourist and ...</td>\n",
       "      <td>27</td>\n",
       "      <td>4.592593</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113167</th>\n",
       "      <td>5d1b9f9e9ad8a11b</td>\n",
       "      <td>OK. First, please understand that not every or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>OK. First, please understand that not every or...</td>\n",
       "      <td>195</td>\n",
       "      <td>4.328205</td>\n",
       "      <td>11</td>\n",
       "      <td>17.727273</td>\n",
       "      <td>33</td>\n",
       "      <td>0.030698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174283</th>\n",
       "      <td>3aa0ef13785f7216</td>\n",
       "      <td>\" \\n :And while I think about it, as you're cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"   :And while I think about it, as you're cre...</td>\n",
       "      <td>35</td>\n",
       "      <td>3.914286</td>\n",
       "      <td>2</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54159</th>\n",
       "      <td>90b9d52928df1655</td>\n",
       "      <td>\"\\n\\n\"\"Sack\"\" is such a loaded word... I think...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"  \"\"Sack\"\" is such a loaded word... I think w...</td>\n",
       "      <td>18</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108285</th>\n",
       "      <td>42d317a2df986ca0</td>\n",
       "      <td>defamatory edits \\nI reverted recent edits mad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>defamatory edits  I reverted recent edits made...</td>\n",
       "      <td>82</td>\n",
       "      <td>4.024390</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>13</td>\n",
       "      <td>0.031026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209620</th>\n",
       "      <td>c76597ba7da569db</td>\n",
       "      <td>==The Great American Bash (2005) - review requ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>==The Great American Bash (2005) - review requ...</td>\n",
       "      <td>33</td>\n",
       "      <td>3.757576</td>\n",
       "      <td>2</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.047059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64255</th>\n",
       "      <td>abf1864aef161562</td>\n",
       "      <td>2004 (UTC)\\nI do not agree, for illustrative p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2004 (UTC) I do not agree, for illustrative pu...</td>\n",
       "      <td>60</td>\n",
       "      <td>4.616667</td>\n",
       "      <td>3</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.017291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80477 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "11037   1d2b1540745088a2  \"\\n\\nOppose, slightly.  While I agree that the...   \n",
       "167471  1fe2936972d58fa8  Yes, he's an academic lawyer, not an academic ...   \n",
       "172810  34bd41d7244721f0  here is a more general discription of a noob \\...   \n",
       "51863   8ad014f3ea982dbf  Kakapo\\nKakapo seems to be a pretty decent art...   \n",
       "94610   fcf2e3270691d13f  Your edit to Norman Cota \\n\\nPlease do not add...   \n",
       "147775  418fc291199679d9  TOM TERRY\\ndont tell me what to do.\\ni apologi...   \n",
       "32126   55612789b2cb5452  \":\"\"around 20,000\"\" is something you have made...   \n",
       "164641  14897717438c761c  == Wikipedia:Wikiportal/Somalia/Featured artic...   \n",
       "235     00958dec64c33224  Please stop adding nonsense to Wikipedia. It i...   \n",
       "57817   9ac50e13e8c8407c                            Two Boys BUmming oohhhh   \n",
       "19656   33ecb2e990e80e26  May 2006 (UTC)\\n\\nI agree Qaid-e-Azam has no r...   \n",
       "124942  9c7364712cce7312  C# doesn't have a criticism section. And all o...   \n",
       "218105  e9e559f02a6d59b1  Did I miss ya? \\n Not sure if you'll get this,...   \n",
       "132282  c3e6693c654aed36  Possibly unfree Image:Algerian_civil_war.jpg \\...   \n",
       "58478   9c99cf3049435b5b  The same editor made the change again, but thi...   \n",
       "101739  2071726aff3fa68f  Thanks, and apologies for starting a new topic...   \n",
       "123485  948dc7c041e2465a  RfC on title of Sarah Brown (wife of Gordon Br...   \n",
       "211130  cd94e2e8d460f446  \" \\n\\n :They are controversies within the scie...   \n",
       "183615  5fe443352a4dbef3  :Thanks for the note and promise not to repeat...   \n",
       "28111   4a653fe8d1811f79                    Block \\nThanks im now unblocked   \n",
       "125271  9e0cca8d8ff27220  \"\\nI agree to some of your claims and apprecia...   \n",
       "75582   ca359b50852b7289  \"\\n\\nSockpuppetry case\\n \\nYou have been accus...   \n",
       "6515    116ac30b7b12be8c  To answer the question, he nominated way too e...   \n",
       "122401  8eb34c63e75edc5f                     Your not gonna do the request?   \n",
       "132470  c4cec2a10dfe4969  I notice the page history of the article was d...   \n",
       "198907  9cb5ff05e652b3df  Is there a source that says the destruction wa...   \n",
       "182053  5961b5e4e7cf7ba7  Sign your statements. Anyways, is this the epi...   \n",
       "39976   6ab31f26b101a2f7  \" August 2009 (UTC)\\nOk, Nev1, it looks like S...   \n",
       "64491   ac957db1e0684d48  I have never seen a 'ben avelign' before.  Whe...   \n",
       "146877  3300a643044afdec         , P.S. I love it when balls are in my face   \n",
       "...                  ...                                                ...   \n",
       "128952  b1a875d91f629169  \"\\n\\nSalut! As you allready saw, he is just wo...   \n",
       "58395   9c54602199fc0523  ip 184, i'm sure you have read this, but pleas...   \n",
       "23620   3e627e043728cce0  or simple rules (any article with 'Day' in the...   \n",
       "209880  c897159b233d9d2a  If contracted/confirmed drivers aren't importa...   \n",
       "126330  a3a5b0fba516ed46  \"\\n\\nHere's why there was no consensus looking...   \n",
       "7568    1421f5f258f434e4  Survey\\n\\nHi Brooke!\\n\\nI have put together a ...   \n",
       "30348   50936ee4686f7c8a  Someone told me! \\nSomeone told me that they w...   \n",
       "77211   cecc33e7ab1573de   Map also needs to be updated with new countries.   \n",
       "19044   324780da50cf8e52  \"\\n\\n Song move \\n\\nYou gave me some good advi...   \n",
       "131312  be93869aa33a2b93  DWO:  Have you even been following the exchang...   \n",
       "203763  b01eeb75aeadb901  GENOCIDE!! \\n this war is pur genocide....you ...   \n",
       "217057  e5aff0e9af237913  == Semi-protected edit request on 17 February ...   \n",
       "77357   cf39a8635e6cfb13  UPDATE: tell me what proof I can give and I'll...   \n",
       "157358  dcbc819e13f7b9cb  . Also please see Talk:Fascism for a section I...   \n",
       "20548   363ce40d4ebc57c2  \"\\n\\nHello!  Because Chris Redfield is a chara...   \n",
       "82413   dc80098c6b319680  \"\\nA poor reference is better than no referenc...   \n",
       "42793   722dc7db8be28042  \"\\n\\n Cunt and \"\"7 Dirty Words\"\" \\n\\nIs the wo...   \n",
       "81552   da1eb55349c101f9  nigger faggot \\n\\nread the entire reference be...   \n",
       "194528  8ba03ba99b545ac4  All God-fearing people are welcome here, infid...   \n",
       "105085  322eab961b4dd2d1  \"\\n\\nI'm going to unprotect the article for th...   \n",
       "109678  4ab41d4570219461  I am a power hungry administrator! Who likes t...   \n",
       "134012  ccc987d2553050cb  \"\\nNow that all of the issues have been addres...   \n",
       "137738  e115df0d9f164424  Interesting - thanks for this.  Suppose that I...   \n",
       "25443   4359b2279ea01527  They complain about the drugs and tourist and ...   \n",
       "113167  5d1b9f9e9ad8a11b  OK. First, please understand that not every or...   \n",
       "174283  3aa0ef13785f7216  \" \\n :And while I think about it, as you're cr...   \n",
       "54159   90b9d52928df1655  \"\\n\\n\"\"Sack\"\" is such a loaded word... I think...   \n",
       "108285  42d317a2df986ca0  defamatory edits \\nI reverted recent edits mad...   \n",
       "209620  c76597ba7da569db  ==The Great American Bash (2005) - review requ...   \n",
       "64255   abf1864aef161562  2004 (UTC)\\nI do not agree, for illustrative p...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "11037       0             0        0       0       0              0   \n",
       "167471      0             0        0       0       0              0   \n",
       "172810      0             0        0       0       0              0   \n",
       "51863       0             0        0       0       0              0   \n",
       "94610       0             0        0       0       0              0   \n",
       "147775      0             0        0       0       0              0   \n",
       "32126       0             0        0       0       0              0   \n",
       "164641      0             0        0       0       0              0   \n",
       "235         0             0        0       0       0              0   \n",
       "57817       0             0        0       0       0              0   \n",
       "19656       0             0        0       0       0              0   \n",
       "124942      0             0        0       0       0              0   \n",
       "218105      0             0        0       0       0              0   \n",
       "132282      0             0        0       0       0              0   \n",
       "58478       0             0        0       0       0              0   \n",
       "101739      0             0        0       0       0              0   \n",
       "123485      0             0        0       0       0              0   \n",
       "211130      0             0        0       0       0              0   \n",
       "183615      0             0        0       0       0              0   \n",
       "28111       0             0        0       0       0              0   \n",
       "125271      0             0        0       0       0              0   \n",
       "75582       0             0        0       0       0              0   \n",
       "6515        0             0        0       0       0              0   \n",
       "122401      0             0        0       0       0              0   \n",
       "132470      0             0        0       0       0              0   \n",
       "198907      0             0        0       0       0              0   \n",
       "182053      1             0        1       0       1              0   \n",
       "39976       0             0        0       0       0              0   \n",
       "64491       0             0        0       0       0              0   \n",
       "146877      1             0        1       0       0              0   \n",
       "...       ...           ...      ...     ...     ...            ...   \n",
       "128952      0             0        0       0       0              0   \n",
       "58395       0             0        0       0       0              0   \n",
       "23620       0             0        0       0       0              0   \n",
       "209880      0             0        0       0       0              0   \n",
       "126330      0             0        0       0       0              0   \n",
       "7568        0             0        0       0       0              0   \n",
       "30348       0             0        0       0       0              0   \n",
       "77211       0             0        0       0       0              0   \n",
       "19044       0             0        0       0       0              0   \n",
       "131312      0             0        0       0       0              0   \n",
       "203763      0             0        0       0       0              0   \n",
       "217057      0             0        0       0       0              0   \n",
       "77357       0             0        0       0       0              0   \n",
       "157358      0             0        0       0       0              0   \n",
       "20548       0             0        0       0       0              0   \n",
       "82413       0             0        0       0       0              0   \n",
       "42793       0             0        0       0       0              0   \n",
       "81552       1             0        1       0       1              1   \n",
       "194528      0             0        0       0       0              0   \n",
       "105085      0             0        0       0       0              0   \n",
       "109678      1             0        1       0       0              0   \n",
       "134012      0             0        0       0       0              0   \n",
       "137738      0             0        0       0       0              0   \n",
       "25443       0             0        0       0       0              0   \n",
       "113167      0             0        0       0       0              0   \n",
       "174283      0             0        0       0       0              0   \n",
       "54159       0             0        0       0       0              0   \n",
       "108285      0             0        0       0       0              0   \n",
       "209620      0             0        0       0       0              0   \n",
       "64255       0             0        0       0       0              0   \n",
       "\n",
       "                                          text_normalized  text_tokens_count  \\\n",
       "11037   \"  Oppose, slightly.  While I agree that the c...                 94   \n",
       "167471  Yes, he's an academic lawyer, not an academic ...                808   \n",
       "172810  here is a more general discription of a noob  ...                 13   \n",
       "51863   Kakapo Kakapo seems to be a pretty decent arti...                 54   \n",
       "94610   Your edit to Norman Cota   Please do not add n...                 27   \n",
       "147775  TOM TERRY dont tell me what to do. i apologize...                 26   \n",
       "32126   \":\"\"around 20,000\"\" is something you have made...                 21   \n",
       "164641  == Wikipedia:Wikiportal/Somalia/Featured artic...                 55   \n",
       "235     Please stop adding nonsense to Wikipedia. It i...                 22   \n",
       "57817                             Two Boys BUmming oohhhh                  4   \n",
       "19656   May 2006 (UTC)  I agree Qaid-e-Azam has no rel...                 33   \n",
       "124942  C# doesn't have a criticism section. And all o...                 56   \n",
       "218105  Did I miss ya?   Not sure if you'll get this, ...                 61   \n",
       "132282  Possibly unfree Image:Algerian_civil_war.jpg  ...                 80   \n",
       "58478   The same editor made the change again, but thi...                 19   \n",
       "101739  Thanks, and apologies for starting a new topic...                 13   \n",
       "123485  RfC on title of Sarah Brown (wife of Gordon Br...                 39   \n",
       "211130  \"    :They are controversies within the scient...                 64   \n",
       "183615  :Thanks for the note and promise not to repeat...                 27   \n",
       "28111                      Block  Thanks im now unblocked                  5   \n",
       "125271  \" I agree to some of your claims and appreciat...                290   \n",
       "75582   \"  Sockpuppetry case   You have been accused o...                 37   \n",
       "6515    To answer the question, he nominated way too e...                 50   \n",
       "122401                     Your not gonna do the request?                  6   \n",
       "132470  I notice the page history of the article was d...                 21   \n",
       "198907  Is there a source that says the destruction wa...                 30   \n",
       "182053  Sign your statements. Anyways, is this the epi...                 47   \n",
       "39976   \" August 2009 (UTC) Ok, Nev1, it looks like Se...                152   \n",
       "64491   I have never seen a 'ben avelign' before.  Whe...                 45   \n",
       "146877         , P.S. I love it when balls are in my face                 11   \n",
       "...                                                   ...                ...   \n",
       "128952  \"  Salut! As you allready saw, he is just worr...                 53   \n",
       "58395   ip 184, i'm sure you have read this, but pleas...                100   \n",
       "23620   or simple rules (any article with 'Day' in the...                 10   \n",
       "209880  If contracted/confirmed drivers aren't importa...                132   \n",
       "126330  \"  Here's why there was no consensus looking a...                 90   \n",
       "7568    Survey  Hi Brooke!  I have put together a surv...                135   \n",
       "30348   Someone told me!  Someone told me that they wa...                 22   \n",
       "77211    Map also needs to be updated with new countries.                  9   \n",
       "19044   \"   Song move   You gave me some good advice a...                277   \n",
       "131312  DWO:  Have you even been following the exchang...                 79   \n",
       "203763  GENOCIDE!!   this war is pur genocide....you m...                159   \n",
       "217057  == Semi-protected edit request on 17 February ...                 12   \n",
       "77357   UPDATE: tell me what proof I can give and I'll...                 15   \n",
       "157358  . Also please see Talk:Fascism for a section I...                 14   \n",
       "20548   \"  Hello!  Because Chris Redfield is a charact...                 28   \n",
       "82413   \" A poor reference is better than no reference...                 69   \n",
       "42793   \"   Cunt and \"7 Dirty Words\"\"   Is the word re...                 51   \n",
       "81552   nigger faggot   read the entire reference befo...                 13   \n",
       "194528  All God-fearing people are welcome here, infid...                 11   \n",
       "105085  \"  I'm going to unprotect the article for the ...                 38   \n",
       "109678  I am a power hungry administrator! Who likes t...                 11   \n",
       "134012  \" Now that all of the issues have been address...                 23   \n",
       "137738  Interesting - thanks for this.  Suppose that I...                122   \n",
       "25443   They complain about the drugs and tourist and ...                 27   \n",
       "113167  OK. First, please understand that not every or...                195   \n",
       "174283  \"   :And while I think about it, as you're cre...                 35   \n",
       "54159   \"  \"\"Sack\"\" is such a loaded word... I think w...                 18   \n",
       "108285  defamatory edits  I reverted recent edits made...                 82   \n",
       "209620  ==The Great American Bash (2005) - review requ...                 33   \n",
       "64255   2004 (UTC) I do not agree, for illustrative pu...                 60   \n",
       "\n",
       "        text_mean_tokens_length  text_sents_count  text_mean_sents_length  \\\n",
       "11037                  4.319149                 5               18.800000   \n",
       "167471                 4.602723                31               26.064516   \n",
       "172810                 3.769231                 1               13.000000   \n",
       "51863                  3.796296                 3               18.000000   \n",
       "94610                  4.555556                 4                6.750000   \n",
       "147775                 3.615385                 3                8.666667   \n",
       "32126                  3.666667                 2               10.500000   \n",
       "164641                 5.763636                 2               27.500000   \n",
       "235                    4.954545                 5                4.400000   \n",
       "57817                  5.000000                 1                4.000000   \n",
       "19656                  3.818182                 3               11.000000   \n",
       "124942                 4.285714                 4               14.000000   \n",
       "218105                 4.098361                 5               12.200000   \n",
       "132282                 4.725000                 6               13.333333   \n",
       "58478                  4.315789                 2                9.500000   \n",
       "101739                 5.538462                 1               13.000000   \n",
       "123485                 3.717949                 2               19.500000   \n",
       "211130                 5.046875                 4               16.000000   \n",
       "183615                 3.925926                 2               13.500000   \n",
       "28111                  5.000000                 1                5.000000   \n",
       "125271                 4.482759                14               20.714286   \n",
       "75582                  5.648649                 4                9.250000   \n",
       "6515                   4.040000                 4               12.500000   \n",
       "122401                 4.000000                 1                6.000000   \n",
       "132470                 4.238095                 2               10.500000   \n",
       "198907                 4.733333                 3               10.000000   \n",
       "182053                 4.021277                 2               23.500000   \n",
       "39976                  3.927632                13               11.692308   \n",
       "64491                  4.422222                 4               11.250000   \n",
       "146877                 2.636364                 2                5.500000   \n",
       "...                         ...               ...                     ...   \n",
       "128952                 3.867925                 7                7.571429   \n",
       "58395                  4.650000                 5               20.000000   \n",
       "23620                  4.000000                 1               10.000000   \n",
       "209880                 4.007576                 8               16.500000   \n",
       "126330                 4.822222                 6               15.000000   \n",
       "7568                   4.674074                12               11.250000   \n",
       "30348                  4.500000                 3                7.333333   \n",
       "77211                  4.333333                 1                9.000000   \n",
       "19044                  4.036101                14               19.785714   \n",
       "131312                 3.987342                 7               11.285714   \n",
       "203763                 4.194969                 2               79.500000   \n",
       "217057                 4.916667                 1               12.000000   \n",
       "77357                  3.266667                 1               15.000000   \n",
       "157358                 4.142857                 1               14.000000   \n",
       "20548                  4.214286                 4                7.000000   \n",
       "82413                  4.304348                 4               17.250000   \n",
       "42793                  5.058824                 5               10.200000   \n",
       "81552                  5.153846                 1               13.000000   \n",
       "194528                 4.545455                 1               11.000000   \n",
       "105085                 5.052632                 4                9.500000   \n",
       "109678                 4.181818                 2                5.500000   \n",
       "134012                 4.521739                 3                7.666667   \n",
       "137738                 4.180328                 5               24.400000   \n",
       "25443                  4.592593                 1               27.000000   \n",
       "113167                 4.328205                11               17.727273   \n",
       "174283                 3.914286                 2               17.500000   \n",
       "54159                  3.722222                 3                6.000000   \n",
       "108285                 4.024390                 6               13.666667   \n",
       "209620                 3.757576                 2               16.500000   \n",
       "64255                  4.616667                 3               20.000000   \n",
       "\n",
       "        text_caps_count  text_caps_ratio  \n",
       "11037                12         0.022989  \n",
       "167471               62         0.013234  \n",
       "172810                6         0.090909  \n",
       "51863                 9         0.033457  \n",
       "94610                 8         0.051282  \n",
       "147775                8         0.065041  \n",
       "32126                 0         0.000000  \n",
       "164641               15         0.039062  \n",
       "235                   5         0.036765  \n",
       "57817                 4         0.173913  \n",
       "19656                11         0.066265  \n",
       "124942               11         0.036184  \n",
       "218105               10         0.031250  \n",
       "132282               13         0.027778  \n",
       "58478                 2         0.019417  \n",
       "101739                1         0.011628  \n",
       "123485               14         0.073298  \n",
       "211130               10         0.024390  \n",
       "183615                3         0.022059  \n",
       "28111                 2         0.066667  \n",
       "125271               33         0.020258  \n",
       "75582                 9         0.035433  \n",
       "6515                 10         0.038462  \n",
       "122401                1         0.033333  \n",
       "132470                2         0.018018  \n",
       "198907                4         0.022989  \n",
       "182053                2         0.008333  \n",
       "39976                51         0.065385  \n",
       "64491                 4         0.015810  \n",
       "146877                3         0.071429  \n",
       "...                 ...              ...  \n",
       "128952                6         0.022222  \n",
       "58395                14         0.024180  \n",
       "23620                 1         0.019231  \n",
       "209880               14         0.020741  \n",
       "126330               10         0.018116  \n",
       "7568                 24         0.030227  \n",
       "30348                 4         0.032520  \n",
       "77211                 1         0.020833  \n",
       "19044                76         0.051317  \n",
       "131312               24         0.058680  \n",
       "203763               29         0.032402  \n",
       "217057                3         0.035714  \n",
       "77357                 8         0.123077  \n",
       "157358                4         0.054795  \n",
       "20548                 7         0.044304  \n",
       "82413                14         0.037037  \n",
       "42793                13         0.039514  \n",
       "81552                 0         0.000000  \n",
       "194528                2         0.032258  \n",
       "105085                3         0.012346  \n",
       "109678                2         0.034483  \n",
       "134012                3         0.022222  \n",
       "137738               24         0.036697  \n",
       "25443                 1         0.006579  \n",
       "113167               33         0.030698  \n",
       "174283                3         0.016043  \n",
       "54159                 4         0.040000  \n",
       "108285               13         0.031026  \n",
       "209620                8         0.047059  \n",
       "64255                 6         0.017291  \n",
       "\n",
       "[80477 rows x 15 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_tokens_count          1250.0\n",
       "text_mean_tokens_length    1240.0\n",
       "text_sents_count            545.0\n",
       "text_mean_sents_length     1250.0\n",
       "text_caps_count            4960.0\n",
       "text_caps_ratio               1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['text_tokens_count', 'text_mean_tokens_length', 'text_sents_count', 'text_mean_sents_length', 'text_caps_count', 'text_caps_ratio']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tokens in comment with the most tokens: 1832 \n",
    "\n",
    "The max mean token length of all comments: 1240 \n",
    "\n",
    "The number of sents in comment with the most sents: 545 \n",
    "\n",
    "The max mena sent length of all comments: 1250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_tokens_count          0.0\n",
       "text_mean_tokens_length    0.0\n",
       "text_sents_count           1.0\n",
       "text_mean_sents_length     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['text_tokens_count', 'text_mean_tokens_length', 'text_sents_count', 'text_mean_sents_length', 'text_caps_count', 'text_caps_ratio'\n",
    "      ]].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic                       0.096748\n",
       "severe_toxic                0.008599\n",
       "obscene                     0.055308\n",
       "threat                      0.003330\n",
       "insult                      0.051244\n",
       "identity_hate               0.009841\n",
       "text_tokens_count          68.994669\n",
       "text_mean_tokens_length     4.485920\n",
       "text_sents_count            4.407259\n",
       "text_mean_sents_length     15.759635\n",
       "text_caps_count            18.397468\n",
       "text_caps_ratio             0.052348\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', \n",
    "          'text_tokens_count', 'text_mean_tokens_length', 'text_sents_count', 'text_mean_sents_length', 'text_caps_count', 'text_caps_ratio']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The proportion of toxic ccomments is 9.58%\n",
    "\n",
    "2) The proportion of severe toxic comments is 0.87%\n",
    "\n",
    "3) The proportion of severe toxic in toxic is 9.04%\n",
    "\n",
    "4) The average number of tokens in comment text is 68.5\n",
    "\n",
    "5) The average length of tokens is 4.5\n",
    "\n",
    "6) The average number of sentences in comment text is 4.4\n",
    "\n",
    "7) The average length of sentences is 15.7\n",
    "\n",
    "8) The average number of uppercase characters in comment text is 18.4\n",
    "\n",
    "9) The average uppercase characters ratio in comment text is 5.23%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">severe_toxic</th>\n",
       "      <th colspan=\"3\" halign=\"left\">obscene</th>\n",
       "      <th colspan=\"3\" halign=\"left\">threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>...</th>\n",
       "      <th>text_sents_count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">text_mean_sents_length</th>\n",
       "      <th colspan=\"3\" halign=\"left\">text_caps_count</th>\n",
       "      <th colspan=\"3\" halign=\"left\">text_caps_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>...</td>\n",
       "      <td>545</td>\n",
       "      <td>15.303643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>14.763974</td>\n",
       "      <td>0</td>\n",
       "      <td>4512</td>\n",
       "      <td>0.045559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088877</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544567</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502569</td>\n",
       "      <td>...</td>\n",
       "      <td>313</td>\n",
       "      <td>20.016831</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>52.320190</td>\n",
       "      <td>0</td>\n",
       "      <td>4960</td>\n",
       "      <td>0.115731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.998189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      severe_toxic           obscene            threat            insult  ...  \\\n",
       "              mean min max      mean min max      mean min max      mean  ...   \n",
       "toxic                                                                     ...   \n",
       "0         0.000000   0   0  0.002903   0   1  0.000193   0   1  0.002903  ...   \n",
       "1         0.088877   0   1  0.544567   0   1  0.032623   0   1  0.502569  ...   \n",
       "\n",
       "      text_sents_count text_mean_sents_length                    \\\n",
       "                   max                   mean       min     max   \n",
       "toxic                                                             \n",
       "0                  545              15.303643  0.000000  1250.0   \n",
       "1                  313              20.016831  0.666667  1247.0   \n",
       "\n",
       "      text_caps_count           text_caps_ratio                 \n",
       "                 mean min   max            mean  min       max  \n",
       "toxic                                                           \n",
       "0           14.763974   0  4512        0.045559  0.0  1.000000  \n",
       "1           52.320190   0  4960        0.115731  0.0  0.998189  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('toxic')['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', \n",
    "            'text_tokens_count', 'text_mean_tokens_length', 'text_sents_count', 'text_mean_sents_length', 'text_caps_count', 'text_caps_ratio'].agg(['mean', 'min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing toxic and non-toxic, the following conclusions can be drawn:\n",
    "\n",
    "1) On average, the number of tokens in toxic comments is less than that in non-toxic comments, which means the toxic comments are shorter\n",
    "\n",
    "2) The sents in toxic comments is longer than in non-toxic comments.\n",
    "\n",
    "3) The average word length is comparable, but in toxic comments is slightly more.\n",
    "\n",
    "4) The average number of sents is comparable, but in toxic comments is slightly less.\n",
    "\n",
    "5) There are more uppercase characters in toxic comments\n",
    "\n",
    "6) Percentage of uppercase characters also in toxic texts more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бейзлайн модель из sklearn (векторайзер + модель) с отбором признаков (через l1 регуляризацию, на глаз через анализ важных параметров или через permutation importance) - 2 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(3, 5), max_df=0.5, min_df=20, max_features=10000)\n",
    "X = CVectorizer.fit_transform(train.comment_text)\n",
    "y = train.toxic.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR_1 (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LR_1 = LogisticRegression(C=0.1, max_iter=10000)\n",
    "LR_1 = LR_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = LR_1.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, y_pred, test_preds):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    p = precision_score(y_test, y_pred, average='binary')\n",
    "    r = recall_score(y_test, y_pred, average='binary') \n",
    "    roc_auc = roc_auc_score(y_test, test_preds)\n",
    "    \n",
    "    print('acc = {0:1.4f}'.format(acc))\n",
    "    print('F1 = {0:1.4f}'.format(f1))\n",
    "    print('Precision = {0:1.4f}'.format(p))\n",
    "    print('Recall = {0:1.4f}'.format(r))\n",
    "    print('ROC AUC = {0:1.4f}'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9489\n",
      "F1 = 0.6962\n",
      "Precision = 0.8053\n",
      "Recall = 0.6131\n",
      "ROC AUC = 0.9366\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LR_2 = LogisticRegression(C=0.05, max_iter=10000)\n",
    "LR_2 = LR_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = LR_2.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9487\n",
      "F1 = 0.6883\n",
      "Precision = 0.8215\n",
      "Recall = 0.5923\n",
      "ROC AUC = 0.9385\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVectorizer = TfidfVectorizer(ngram_range=(3, 5), max_df=0.9, min_df=0.01, max_features=10000)\n",
    "X = TVectorizer.fit_transform(train.comment_text)\n",
    "y = train.toxic.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LR_3 = LogisticRegression(C=0.1, max_iter=10000)\n",
    "LR_3 = LR_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = LR_3.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9044\n",
      "F1 = 0.0000\n",
      "Precision = 0.0000\n",
      "Recall = 0.0000\n",
      "ROC AUC = 0.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "LR_4 = LogisticRegression(C=0.05, max_iter=10000)\n",
    "LR_4 = LR_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = LR_4.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9044\n",
      "F1 = 0.0000\n",
      "Precision = 0.0000\n",
      "Recall = 0.0000\n",
      "ROC AUC = 0.5738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, y_pred, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>x8447</td>\n",
       "      <td>1.151589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>x4391</td>\n",
       "      <td>0.910716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>x3409</td>\n",
       "      <td>0.874820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>x5535</td>\n",
       "      <td>0.863148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>x8840</td>\n",
       "      <td>0.852480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target feature    weight\n",
       "0       1   x8447  1.151589\n",
       "1       1   x4391  0.910716\n",
       "2       1   x3409  0.874820\n",
       "3       1   x5535  0.863148\n",
       "4       1   x8840  0.852480"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_features = eli5.formatters.as_dataframe.explain_weights_df(LR_1)\n",
    "top_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = [int(i[1:]) for i in top_features.feature if 'BIAS' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shit\n",
      "full\n",
      "e). \n",
      "jew \n",
      "tar \n"
     ]
    }
   ],
   "source": [
    "id2word = {v:k for k,v in CVectorizer.vocabulary_.items()}\n",
    "for i in top_features[:5]:\n",
    "  print(id2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eli5 = X_train[:,top_features]\n",
    "test_eli5 = X_test[:,top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_eli5 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9282351731441564"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_eli5 = LR_1.fit(train_eli5, y_train)\n",
    "test_preds = LR_eli5.predict_proba(test_eli5)[:, 1]\n",
    "roc_auc_score(y_test,test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбль из моделей в sklearn (ансамблевые модели типа randomforest не считаются). Нужно минимум 5 разных моделей - 2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = LogisticRegression()\n",
    "m2 = GaussianNB()\n",
    "m3 = MultinomialNB()\n",
    "m4 = SVC()\n",
    "m5 = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['comment_text']\n",
    "y = train['toxic']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=[\n",
    "        ('m1', m1), ('m2', m2), ('m3', m3), ('m4', m4), ('m5', m5)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "voting = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='word', max_features=200)),\n",
    "    ('tfidf', TfidfTransformer(sublinear_tf=True)),\n",
    "    ('to_dense', FunctionTransformer(lambda x: x.todense(), accept_sparse=True)), \n",
    "    ('clf', vc),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "voting = voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "preds = voting.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:   0.91\n",
      "F1-measure:   0.60\n",
      "Precision:   0.84\n",
      "Recall:   0.57\n"
     ]
    }
   ],
   "source": [
    "print(\"Acc: {0:6.2f}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, preds, average='macro')))\n",
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, preds, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, preds, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любая нейронная модель (минимум 5 слоев) с Dropout, Pooling и колбеками - 2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text): \n",
    "    tokens = re.findall('[a-zA-Z]+|[\\.\\?!,—]', text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['comment_tokens'] = train['text_normalized'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37403     [I, ve, conceeded, that, its, pointless, askin...\n",
       "58848     [Wikipedia, articles, are, not, the, place, to...\n",
       "127175    [Read, what, I, wrote, above, !, !, Please, !,...\n",
       "51173     [Finally, ,, some, kind, of, answer, to, my, q...\n",
       "1977      [You, cannot, take, a, practice, engaged, in, ...\n",
       "80142     [Uh, ,, how, is, editing, my, own, talk, page,...\n",
       "84857     [And, tell, that, liz, creep, that, how, can, ...\n",
       "170310    [., I, have, the, right, to, free, speech, and...\n",
       "93228     [Some, more, vandalism, as, per, DanielRigal, ...\n",
       "4372      [Well, ,, at, least, it, s, a, step, in, the, ...\n",
       "Name: comment_tokens, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_n = train['comment_tokens']\n",
    "y_n = train['toxic']\n",
    "X_n[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_n_train, X_n_test, y_n_train, y_n_test = train_test_split(X_n, y_n, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_n_train\n",
    "y_t = y_n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for i in X_n_train:\n",
    "    vocab.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116090"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set([token for token in vocab if vocab[token] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22234"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2id = {'UNK':1, 'PAD':0}\n",
    "\n",
    "for token in filtered_vocab:\n",
    "    token2id[token] = len(token2id)\n",
    "    \n",
    "id2token = {i:token for token, i in token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2ids(tokens):\n",
    "    ids = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            ids.append(token2id[token])\n",
    "        except KeyError:\n",
    "            ids.append(1)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_id = [text2ids(tokens) for tokens in X_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3848"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = max([len(tokens) for tokens in X_t])\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad = tf.keras.preprocessing.sequence.pad_sequences(X_t_id, maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_pad, y_t, test_size=0.05, stratify=y_t, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_ouc = tf.keras.metrics.AUC(\n",
    "    num_thresholds=200, curve='ROC', summation_method='interpolation', name=None,\n",
    "    dtype=None, thresholds=None, multi_label=False, label_weights=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', monitor='val_f1', verbose=1, save_weights_only=True,\n",
    "                                                save_best_only=True, mode='max', save_freq='epoch' )\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_f1', min_delta=0.01, patience=3, verbose=1, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(int(MAX_LEN),))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(token2id), output_dim=500)(inputs)\n",
    "\n",
    "drop1 = tf.keras.layers.Dropout(0.2)(embeddings)\n",
    "conv1 = tf.keras.layers.Conv1D(kernel_size=3, filters=32, padding='same', strides=1)(drop1)\n",
    "pool1 = pool1 = tf.compat.v1.keras.layers.MaxPool1D()(conv1)\n",
    "conv2 = tf.keras.layers.Conv1D(kernel_size=2, filters=10, padding='same', strides=1)(pool1)\n",
    "pool2 = pool1 = tf.compat.v1.keras.layers.MaxPool1D()(conv2)\n",
    "conv3 = tf.keras.layers.Conv1D(kernel_size=2, filters=5, padding='same', strides=1)(pool2)\n",
    "pool3 = tf.compat.v1.keras.layers.MaxPool1D()(conv3)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(pool3)\n",
    "dense = tf.keras.layers.Dense(50, activation='relu')(flatten)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[f1, roc_ouc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48164 samples, validate on 2535 samples\n",
      "Epoch 1/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.4861 - f1: 0.0326 - auc_1: 0.4642\n",
      "Epoch 00001: val_f1 improved from -inf to 0.01026, saving model to model.weights\n",
      "48164/48164 [==============================] - 51s 1ms/sample - loss: 0.4856 - f1: 0.0313 - auc_1: 0.4644 - val_loss: 0.3131 - val_f1: 0.0103 - val_auc_1: 0.6903\n",
      "Epoch 2/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.2873 - f1: 0.0363 - auc_1: 0.7286\n",
      "Epoch 00002: val_f1 improved from 0.01026 to 0.07450, saving model to model.weights\n",
      "48164/48164 [==============================] - 51s 1ms/sample - loss: 0.2876 - f1: 0.0348 - auc_1: 0.7292 - val_loss: 0.2693 - val_f1: 0.0745 - val_auc_1: 0.8043\n",
      "Epoch 3/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.2318 - f1: 0.2341 - auc_1: 0.8691\n",
      "Epoch 00003: val_f1 improved from 0.07450 to 0.44053, saving model to model.weights\n",
      "48164/48164 [==============================] - 50s 1ms/sample - loss: 0.2316 - f1: 0.2432 - auc_1: 0.8695 - val_loss: 0.2109 - val_f1: 0.4405 - val_auc_1: 0.8882\n",
      "Epoch 4/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.1638 - f1: 0.5747 - auc_1: 0.9405\n",
      "Epoch 00004: val_f1 improved from 0.44053 to 0.63749, saving model to model.weights\n",
      "48164/48164 [==============================] - 52s 1ms/sample - loss: 0.1636 - f1: 0.5688 - auc_1: 0.9405 - val_loss: 0.1812 - val_f1: 0.6375 - val_auc_1: 0.9208\n",
      "Epoch 5/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.1130 - f1: 0.7422 - auc_1: 0.9740\n",
      "Epoch 00005: val_f1 improved from 0.63749 to 0.67827, saving model to model.weights\n",
      "48164/48164 [==============================] - 52s 1ms/sample - loss: 0.1130 - f1: 0.7431 - auc_1: 0.9740 - val_loss: 0.1685 - val_f1: 0.6783 - val_auc_1: 0.9324\n",
      "Epoch 6/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0789 - f1: 0.8362 - auc_1: 0.9876\n",
      "Epoch 00006: val_f1 improved from 0.67827 to 0.68514, saving model to model.weights\n",
      "48164/48164 [==============================] - 52s 1ms/sample - loss: 0.0789 - f1: 0.8352 - auc_1: 0.9877 - val_loss: 0.1851 - val_f1: 0.6851 - val_auc_1: 0.9316\n",
      "Epoch 7/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0637 - f1: 0.8700 - auc_1: 0.9922\n",
      "Epoch 00007: val_f1 did not improve from 0.68514\n",
      "48164/48164 [==============================] - 51s 1ms/sample - loss: 0.0639 - f1: 0.8703 - auc_1: 0.9921 - val_loss: 0.1912 - val_f1: 0.6764 - val_auc_1: 0.9286\n",
      "Epoch 8/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0429 - f1: 0.9248 - auc_1: 0.9964\n",
      "Epoch 00008: val_f1 did not improve from 0.68514\n",
      "48164/48164 [==============================] - 50s 1ms/sample - loss: 0.0429 - f1: 0.9265 - auc_1: 0.9964 - val_loss: 0.2073 - val_f1: 0.6746 - val_auc_1: 0.9117\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29f26025408>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         validation_data=(X_valid, y_valid),\n",
    "         epochs=50,\n",
    "         batch_size=2000,\n",
    "         callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('rocout_toxic_model.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'f1', 'auc_1', 'val_loss', 'val_f1', 'val_auc_1'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "plt.plot(model.history.history['f1'])\n",
    "plt.plot(model.history.history['val_f1'])\n",
    "plt.title('model_f1')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(int(MAX_LEN),))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(token2id), output_dim=100)(inputs)\n",
    "convs = []\n",
    "\n",
    "drop1 = tf.keras.layers.Dropout(0.2)(embeddings)\n",
    "conv1 = tf.keras.layers.Conv1D(kernel_size=3, filters=32, padding='same', strides=1)(drop1)\n",
    "conv2 = tf.keras.layers.Conv1D(kernel_size=2, filters=10, padding='same', strides=1)(conv1)\n",
    "conv3 = tf.keras.layers.Conv1D(kernel_size=2, filters=5, padding='same', strides=1)(conv2)\n",
    "conv4 = tf.keras.layers.Conv1D(kernel_size=2, filters=5, padding='same', strides=1)(conv3)\n",
    "pool1 = tf.compat.v1.keras.layers.MaxPool1D()(conv4)\n",
    "convs.append(pool1)\n",
    "\n",
    "drop2 = tf.keras.layers.Dropout(0.1)(embeddings)\n",
    "conv5 =  tf.keras.layers.Conv1D(kernel_size=10, filters=5, padding='same', strides=1)(drop2)\n",
    "pool2 = tf.compat.v1.keras.layers.MaxPool1D()(conv5)\n",
    "convs.append(pool2)\n",
    "\n",
    "drop3 = tf.keras.layers.Dropout(0.1)(embeddings)\n",
    "conv6 = tf.keras.layers.Conv1D(kernel_size=2, filters=10, padding='same', strides=1)(drop3)\n",
    "conv7 = tf.keras.layers.Conv1D(kernel_size=4, filters=5, padding='same', strides=1)(conv6)\n",
    "pool3 = tf.compat.v1.keras.layers.MaxPool1D()(conv7)\n",
    "convs.append(pool3)\n",
    "\n",
    "drop4 = tf.keras.layers.Dropout(0.2)(embeddings)\n",
    "conv8 = tf.keras.layers.Conv1D(kernel_size=2, filters=5, padding='same', strides=1)(drop4)\n",
    "pool4 = tf.compat.v1.keras.layers.MaxPool1D()(conv8)\n",
    "convs.append(pool4)\n",
    "\n",
    "concat = tf.keras.layers.concatenate(convs, axis=1)\n",
    "conv_global = tf.keras.layers.Conv1D(kernel_size=5, filters=32, strides=1)(concat)\n",
    "flatten = tf.keras.layers.Flatten()(conv_global)\n",
    "dense = tf.keras.layers.Dense(50, activation='relu')(flatten)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[f1, roc_ouc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48164 samples, validate on 2535 samples\n",
      "Epoch 1/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.3626 - f1: 0.0110 - auc_1: 0.5750\n",
      "Epoch 00001: val_f1 did not improve from 0.64969\n",
      "48164/48164 [==============================] - 42s 873us/sample - loss: 0.3625 - f1: 0.0106 - auc_1: 0.5756 - val_loss: 0.2871 - val_f1: 0.0000e+00 - val_auc_1: 0.7795\n",
      "Epoch 2/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.2392 - f1: 0.0587 - auc_1: 0.8653\n",
      "Epoch 00002: val_f1 did not improve from 0.64969\n",
      "48164/48164 [==============================] - 41s 850us/sample - loss: 0.2390 - f1: 0.0678 - auc_1: 0.8657 - val_loss: 0.2011 - val_f1: 0.3287 - val_auc_1: 0.9056\n",
      "Epoch 3/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.1549 - f1: 0.6068 - auc_1: 0.9485\n",
      "Epoch 00003: val_f1 improved from 0.64969 to 0.67918, saving model to model.weights\n",
      "48164/48164 [==============================] - 42s 866us/sample - loss: 0.1549 - f1: 0.6082 - auc_1: 0.9484 - val_loss: 0.1764 - val_f1: 0.6792 - val_auc_1: 0.9247\n",
      "Epoch 4/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0959 - f1: 0.7927 - auc_1: 0.9825\n",
      "Epoch 00004: val_f1 did not improve from 0.67918\n",
      "48164/48164 [==============================] - 43s 888us/sample - loss: 0.0959 - f1: 0.7888 - auc_1: 0.9825 - val_loss: 0.2029 - val_f1: 0.6651 - val_auc_1: 0.9136\n",
      "Epoch 5/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0638 - f1: 0.8755 - auc_1: 0.9917\n",
      "Epoch 00005: val_f1 did not improve from 0.67918\n",
      "48164/48164 [==============================] - 43s 897us/sample - loss: 0.0638 - f1: 0.8756 - auc_1: 0.9917 - val_loss: 0.2164 - val_f1: 0.6640 - val_auc_1: 0.9088\n",
      "Epoch 6/50\n",
      "48000/48164 [============================>.] - ETA: 0s - loss: 0.0417 - f1: 0.9246 - auc_1: 0.9965\n",
      "Epoch 00006: val_f1 did not improve from 0.67918\n",
      "48164/48164 [==============================] - 43s 889us/sample - loss: 0.0419 - f1: 0.9213 - auc_1: 0.9965 - val_loss: 0.2521 - val_f1: 0.6784 - val_auc_1: 0.8870\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29f275c6088>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "         validation_data=(X_valid, y_valid),\n",
    "         epochs=50,\n",
    "         batch_size=2000,\n",
    "         callbacks=[checkpoint, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'f1', 'auc_1', 'val_loss', 'val_f1', 'val_auc_1'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "plt.plot(model.history.history['f1'])\n",
    "plt.plot(model.history.history['val_f1'])\n",
    "plt.title('model_f1')\n",
    "plt.ylabel('f1')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строка 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование токенизации на символьные нграммы (не параметром analyzer=’char’, а вручную или готовым энструментов вроде youtokentome - 2 балла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_yttm = '\\n'.join(X_train.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'yttm_train_data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_data, 'w') as f:\n",
    "  f.write(X_train_yttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "yttm_model = 'yttm.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtokentome.youtokentome.BPE at 0x29da2fb5408>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yttm.BPE.train(data=train_data, vocab_size=100000, model=yttm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_model = yttm.BPE(model=yttm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_comments = bpe_model.encode(train.comment_text.tolist(), output_type=yttm.OutputType.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['encoded_comments'] = encoded_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁\"',\n",
       " '▁Oppose',\n",
       " ',',\n",
       " '▁slightly.',\n",
       " '▁While',\n",
       " '▁I',\n",
       " '▁agree',\n",
       " '▁that',\n",
       " '▁the',\n",
       " '▁current']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bpe_model.id_to_subword(num) for num in encoded_comments[0]][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
